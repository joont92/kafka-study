- 처음 단순하게 1개의 컨슈머로 시스템을 구성한다면 아래의 그림이 될 것이다
    - ![](~/workspace/kafka-study/img/consumer-group-01.png)
- 만약 프로듀서가 메시지를 보내는 속도가 컨슈머가 메시지를 consume 하는 속도보다 더 빨라진다면, 컨슈머의 개수를 늘려야만 한다
    - 컨슈머의 개수를 늘린다는건 인스턴스의 개수를 늘리는 것을 말한다
    - 하지만 단순히 인스턴스의 개수를 늘리면, 동일한 메시지를 늘어난 인스턴스 개수만큼 받게되는 문제가 발생한다
        - 인스턴스 각각을 개별 컨슈머라고 생각하기 때문이다(물론 틀린말은 아니지만..)
- 카프카에서는 동일한 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 하는 `컨슈머 그룹`이라는 기능을 제공한다
    - 단순하게 말해 컨슈머를 하나의 그룹으로 묶는것이다
    - 이를 사용하면 위의 문제점을 해결할 수 있다


- 컨슈머 그룹을 설정한 모습은 아래와 같다
    - ![](~/workspace/kafka-study/img/consumer-group-02.png)
- 컨슈머끼리 lock 을 잡고 데이터를 가져오는 구조가 아니라, **그룹내에 있는 파티션 1개당 컨슈머 1개가 연결되는 구조**이다
- 컨슈머의 개수가 파티션의 개수보다 적으면 파티션 1개에 n 개의 컨슈머가 연결되게 된다
    - ![](~/workspace/kafka-study/img/consumer-group-03.png)
- 컨슈머의 개수가 파티션의 개수보다 많으면 **남는 컨슈머는 메시지를 컨슘하지 못한다**
    - ![](~/workspace/kafka-study/img/consumer-group-04.png)
    - 파티션 1개에 컨슈머 1개만 연결될 수 있기 때문이다
        - 위의 예제에서는 이 룰을 벗어나지 않았다
    - 결국 파티션 개수만큼 최대 컨슈머 수가 연결할 수 있다
        - 즉, **프로듀서의 속도가 컨슈머의 속도보다 빠르다고 할 때 무작정 컨슈머의 개수를 늘릴 것이 아니라, 파티션의 개수를 늘리고 그에 맞춰 컨슈머의 개수를 늘려줘야 한다**


- 몇번 파티션에 어떤 컨슈머가 매핑되어 있는지는 zookeeper(?)에 기록된다
    - 새로 들어온 컨슈머가 파티션을 점유하려면, 자기가 쓸 수 있는 파티션이 무엇인지 알아야하기 때문이다
- 컨슈머의 개수가 변동이 있을 경우 계속해서 이 정보가 갱신된다
    - `파티션 : 컨슈머` 매핑을 변경하는 것을 말한다
    - 이를 `리밸런싱`이라고 한다
    - 리밸런스하는 동안에 컨슈머는 일시적으로 메시지를 가져올 수 없다
    - e.g. 파티션 4개, 컨슈머 4개인 상태에서 컨슈머 1개가 다운되면, 컨슈머 1개가 2개의 파티션 메시지를 컨슘하도록 리밸런싱 된다
- 컨슈머는 주기적으로 zookeeper(?)에 하트비트를 보낸다
    - 컨슈머가 살아있다는 신호를 주기적으로 보내주는 것이다
    - zookeeper(?) 입장에서 하트비트를 일정시간 이상 받지 못하면 해당 컨슈머가 죽었다고 판단하고 리밸런싱을 시도하게 된다
    - 컨슈머가 메시지를 poll 하거나 가져간 메시지의 오프셋을 보낼 때 하트비트를 보낸다


- 컨슈머 그룹마다 오프셋을 따로 관리하므로, 추가로 메시지를 컨슘하고 싶을 경우 중복되지 않는 컨슈머 그룹 id 만 설정한 뒤 메시지를 컨슘하면 된다
    - 확장에 매우 용이하다!